# Projeto BEMU

Nesse reposit√≥rio disponibilizamos o c√≥digo utilizado no projeto BEMU (Benchmarks Educacionais Multimodais Universi√°rias) realizado pelo RAIA como parte de uma colabora√ß√£o de um projeto maior, a ser anunciado em breve. O projeto teve como objetivo realizar uma coleta de dados para a cria√ß√£o de uma nova benchmark multimodal (i.e. que contempla mais de uma modalidade de entrada; consideramos as modalidades de texto e imagem) com perguntas de vestibulares brasileiros, os quais n√£o s√≥ possuem dados nativos em PT-br como tamb√©m s√£o ricos em conhecimentos espec√≠ficos relacionados a cultura brasileira. Para mais detalhes sobre o projeto recomendamos uma leitura do nosso [artigo no Medium](https://medium.com/@raia.diretoria/indo-al%C3%A9m-do-ingl%C3%AAs-ampliando-o-horizonte-de-avalia%C3%A7%C3%B5es-de-ias-multimodais-a5249af02f7a).

O c√≥digo disponibilizado pode ser utilizado para a a extra√ß√£o de dados de PDFs usando uma estrat√©gia h√≠brida, ou seja, que se utiliza tanto de bibliotecas de parsing quanto MLLMs (e.g. Gemini 1.5) para coletar os dados desejados como ilustrado no diagrama abaixo. O resulado final √© um dataset √∫nico em .json com enunciado, alternativas, imagens e metadados para cada uma quest√£o das provas passadas.

<p align="center">
<img src=
"./img/BEMU_diagram.png"
width="80%">
<p align="center">
<em>Pipeline de extra√ß√£o de dados utilizada.</em>
</p> 
</p> 

O c√≥digo providenciado pode ser usado para extrair dados e formatar provas de m√∫ltipla escolha no geral, por√©m devido a pequenas varia√ß√µes entre provas em termos de estrutura notamos que algumas fun√ß√µes providenciadas est√£o sujeitas a mudan√ßas para o funcionamento ideal do c√≥digo. Contudo, acreditamos que ele possa servir como uma template s√≥lido para a realiza√ß√£o desse tipo de tarefa.

## ü§ó Datasets

O projeto foi realizado como uma colabora√ß√£o em um projeto de maior escala. Dessa forma, vamos adiar o lan√ßamento dos dados at√© o in√≠cio de Mar√ßo para que todos os detalhes sejam lan√ßados de maneira s√≠ncrona.

## üìö Entrada esperada
Devido a dificuldade de convers√£o manual de express√µes matem√°ticas e de f√≥rmulas qu√≠micas de maneira padronizada utilizamos o Mathpix para extrair os dados presentes nos PDFs das provas e convert√™-los para LaTeX, al√©m de fazer a extra√ß√£o de imagens presentes nos documentos. O uso dessa plataforma n√£o √© necess√°ria (por√©m altamente recomendado dados os [desafios encontrados durante a extra√ß√£o](https://medium.com/@raia.diretoria/indo-al%C3%A9m-do-ingl%C3%AAs-ampliando-o-horizonte-de-avalia%C3%A7%C3%B5es-de-ias-multimodais-a5249af02f7a))), por√©m o script de extra√ß√£o de dados espera uma estrutura de diret√≥rios e arquivos como ilustrada abaixo para seu funcionamento, com uma pasta para cada ano e dentro dela um arquivo .tex com os conte√∫dos das provas e outro com os dados do gabarito.

```
.
‚îî‚îÄ‚îÄ UNESP
    ‚îú‚îÄ‚îÄ 2014
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ images
    ‚îÇ   ‚îú‚îÄ‚îÄ prova.tex
    ‚îÇ   ‚îî‚îÄ‚îÄ gabarito.tex
    ‚îú‚îÄ‚îÄ 2015
    ‚îú‚îÄ‚îÄ 2016
    ‚îú‚îÄ‚îÄ 2017
    ...
    ‚îî‚îÄ‚îÄ 2025
```
## üìë Formato do dataset

Como observado acima, o script resulta na cria√ß√£o de um dataset √∫nico por prova armazenado em um .json. Cada elemento do arquivo representa uma quest√£o, a qual possui as seguinte informa√ß√µes:
```Python
    questao = {
        'language': 'pt', #Idioma da quest√£o.
        'country': 'Brazil', # Pa√≠s de origem da quest√£o.
        'file_name': '', # Nome do arquivo onde a quest√£o est√° armazenada.
        'source' : '', # Fonte da quest√£o.
        'license': 'Unknown', # Licen√ßa da quest√£o.
        'level' : 'University Entrance', # N√≠vel de dificuldade da quest√£o.
        'category_en' : '', # Categoria da quest√£o em ingl√™s.
        'category_original_lang' : '', # Categoria da quest√£o no idioma original.
        'original_question_num' : -1, # N√∫mero original da quest√£o.
        'question' : '', # Enunciado.
        'options' : [], # Alternativas.
        'answer' : '', # Resposta correta (index de 0 a 3 de acordo com o valor em "options").
        'image_png' : '', # Caminho para a imagem associada √† quest√£o.
        'image_information' : None, # Se a imagem √© essencial ou n√£o para o entendimento da quest√£o.
        'image_type' : None, # Tipo de imagem (e.g. diagrama, tabela).
        'parallel_question_id' : None # ID de uma quest√£o paralela, se houver.
    }
```

Abaixo mostramos um exemplo de uma quest√£o depois de processada:
```Python
{
    "language": "pt", 
    "country": "Brazil", 
    "file_name": "UNESP2014_1fase_prova", 
    "source": "https://www.curso-objetivo.br/vestibular/resolucao-comentada/unesp/2014/1fase/UNESP2014_1fase_prova.pdf", 
    "license": "Unknown", 
    "level": "University Entrance", 
    "category_en": "English", 
    "category_original_lang": "Ingl√™s", 
    "original_question_num": 21, 
    "question": "Examine o quadrinho.\n\n\nO homem responde que a empresa", 
    "options": ["utiliza pr√°ticas de conserva√ß√£o ambiental e de reciclagem de papel.", 
        "tem uma publica√ß√£o que pretende parecer ambientalmente correta.", 
        "trabalha somente com mat√©rias-primas naturais de fontes renov√°veis.", 
        "esclarece todas as d√∫vidas sobre o meio ambiente em seu livreto."], 
    "answer": 1, 
    "image_png": "unesp_2014_21_2025_01_24_7db1472f3078959911e1g-07.png", 
    "image_information": "essential", 
    "image_type": "text", 
    "parallel_question_id": null}
```

<details>
  <summary> Observa√ß√µes acerca do formato </summary>

Para garantir a qualidade dos dados mantivemos algumas etapas de corre√ß√£o manual. Para esses casos, escrevemos algumas fun√ß√µes respons√°veis por detectar anomalias comuns resultantes de erros de parsing (e.g. quest√£o sem t√≠tulo, mais de uma imagem em uma mesma quest√£o). Notamos tamb√©m que algumas verifica√ß√µes n√£o s√£o estritamente necess√°rias, como limitar uma imagem apenas por enunciado, mas foram tomadas para padronizar os datasets e torn√°-los mais f√°ceis de serem utilizados para fins avaliativos.

</details>



## üõ†Ô∏è Como executar o c√≥digo

Primeiro devemos criar um environment usando [Anaconda](https://www.anaconda.com/) onde todas as depend√™ncias ser√£o baixadas (optamos pelo uso de Anaconda mas o mesmo pode ser feito usando outras ferramentas como venv ou uv):
```Bash
conda create -n "bemu" python=3.10.14 ipython
conda activate bemu
```

Em seguida, o projeto √© clonado e baixamos as depend√™ncias necess√°rias para a execu√ß√£o do c√≥digo :
```Bash
git clone https://github.com/gruporaia/BEMU.git
cd BEMU
pip install -r requirements.txt
```

Antes de executar o c√≥digo, altere informa√ß√µes da vari√°vel global `SOURCE_DICT` e das fun√ß√µes `translate_subject()` e `prompt_gemini_subject()` para que ela se adeque ao seu contexto das suas provas. Al√©m disso, como utilizamos o Gemini 1.5 como ferramenta para auxiliar a coleta de alguns metadados relacionados a imagens √© necess√°rio que uma chave de API seja [criada](https://ai.google.dev/gemini-api/docs/api-key) e designada a uma vari√°vel global no seu ambiente executando o comando:
```Bash
export GEMINI_API_KEY=<SUA_CHAVE>
```

Finalmente, o c√≥digo de extra√ß√£o pode ser usado rodando o seguinte comando:
```Bash
python process_data.py --prova_dir <DIRETORIO_DAS_PROVAS>
```

Depois da passagem por todas as etapas de pipeline de processamento os dados ser√£o armazenados em um arquivo √∫nico em `<DIRETORIO_DAS_PROVAS>/data.json` e todas as m√≠dias estar√£o dispon√≠veis em `<DIRETORIO_DAS_PROVAS>/images/`.

## üíª Quem somos n√≥s?
| ![LogoRAIA](https://github.com/user-attachments/assets/ce3f8386-a900-43ff-af84-adce9c17abd2) |  Este projeto foi desenvolvido pelos membros do **RAIA (Rede de Avan√ßo de Intelig√™ncia Artificial)**, uma iniciativa estudantil do Instituto de Ci√™ncias Matem√°ticas e de Computa√ß√£o (ICMC) da USP - S√£o Carlos. Somos estudantes que compartilham o objetivo de criar solu√ß√µes inovadoras utilizando intelig√™ncia artificial para impactar positivamente a sociedade. Para saber mais, acesse [nosso site](https://gruporaia.vercel.app/) ou [nosso Instagram](instagram.com/grupo.raia)! |
|------------------|-------------------------------------------|
 
### **Desenvolvedores**
- **Andr√© Mitri** - [LinkedIn](https://www.linkedin.com/in/andre-de-mitri/) | [GitHub](https://github.com/andregdmitri)
- **Leticia Marchezi** - [LinkedIn](https://www.linkedin.com/in/letmarchezi/) | [GitHub](https://github.com/letMarchezi/)
- **Gabriel Merlin** - [LinkedIn](https://www.linkedin.com/in/gabrielcmerlin/) | [GitHub](https://github.com/gabrielcmerlin)
- **Ot√°vio F. Coletti** - [LinkedIn](https://www.linkedin.com/in/ot%C3%A1viocoletti-012/) | [GitHub](https://github.com/otaviofcolett)
- **Lu√≠sa Shimabucoro** - [LinkedIn](https://www.linkedin.com/in/lushimabucoro) | [Website](http://luisashimabucoro.github.io)
